= Démarrer avec AWS Lambda
:revdate: 2025-07-10
:page-revdate: {revdate}
:description: SUSE Observability

Nous allons configurer la surveillance pour une ou plusieurs fonctions AWS Lambda :

* La ou les fonctions AWS Lambda surveillées (instrumentées à l'aide d'Open Telemetry).
* Le collecteur de télémétrie ouvert
* SUSE Observability ou SUSE Cloud Observability

image::otel/open-telemetry-collector-lambda.png[Instrumentation AWS Lambda avec Open Telemetry avec le collecteur Open Telemetry fonctionnant dans Kubernetes.]

== Le collecteur de télémétrie ouvert

[NOTE]
====
Pour une configuration de production, il est fortement recommandé d'installer le collecteur, car il permet à votre service de décharger rapidement les données et le collecteur peut prendre en charge des tâches supplémentaires telles que les tentatives, la mise en lots, le cryptage ou même le filtrage des données sensibles.
====


Tout d'abord, nous allons installer le collecteur OTel (Open Telemetry), dans cet exemple nous utilisons un cluster Kubernetes pour l'exécuter à proximité des fonctions Lambda. Une configuration similaire peut être réalisée en utilisant un collecteur installé sur une machine virtuelle. La configuration utilisée ici agit uniquement comme un proxy sécurisé pour décharger rapidement les données des fonctions Lambda et s'exécute au sein d'une infrastructure réseau de confiance.

=== Créer un jeton de service

Il existe deux façons de créer un jeton de service :

* **SUSE Observability UI** - ouvrez le menu principal en cliquant en haut à gauche de l'écran et allez à `StackPacks` > `Open Telemetry`.  Si vous ne l'avez pas encore fait, cliquez sur le bouton `INSTALL`.  Cliquez sur le bouton `CREATE NEW SERVICE TOKEN` et copiez la valeur dans votre presse-papiers.
* **SUSE Observability CLI** - voir xref:/use/security/k8s-service-tokens.adoc#_manage_service_tokens[Gérer les jetons de service]

La valeur du jeton de service doit être utilisée lorsque les instructions ci-dessous mentionnent `<SERVICE_TOKEN>`.

=== Créer l'espace de noms et un secret pour le jeton de service

Nous l'installerons dans l'espace de noms `open-telemetry` et utiliserons le jeton de service :

[,bash]
----
kubectl create namespace open-telemetry
kubectl create secret generic open-telemetry-collector \
    --namespace open-telemetry \
    --from-literal=API_KEY='<SERVICE_TOKEN>'
----

=== Configurer et installer le collecteur

Nous installons le collecteur à l'aide d'une carte Helm fournie par le projet Open Telemetry. Assurez-vous que le référentiel Open Telemetry helm charts est configuré :

[,bash]
----
helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts
----

Créer un fichier de valeurs `otel-collector.yaml` pour la carte Helm. Voici un bon point de départ pour une utilisation avec SUSE Observability, remplacez `<otlp-suse-observability-endpoint:port>` par votre point de terminaison OTLP (voir xref:/setup/otel/otlp-apis.adoc[OTLP API] pour votre point de terminaison) et insérez le nom de votre cluster Kubernetes à la place de `<your-cluster-name>`. Lorsque vous utilisez la configuration d'entrée, veillez également à insérer votre propre nom de domaine et le secret du certificat TLS correspondant aux endroits indiqués.

.otel-collector.yaml
[,yaml]
----
mode: deployment
presets:
  kubernetesAttributes:
    enabled: true
    # You can also configure the preset to add all the associated pod's labels and annotations to you telemetry.
    # The label/annotation name will become the resource attribute's key.
    extractAllPodLabels: true
extraEnvsFrom:
  - secretRef:
      name: open-telemetry-collector
image:
  repository: "ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-k8s"

config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
  extensions:
    # Use the API key from the env for authentication
    bearertokenauth:
      scheme: SUSEObservability
      token: "${env:API_KEY}"
  exporters:
    otlp:
      auth:
        authenticator: bearertokenauth
      # Put in your own otlp endpoint, for example otlp-suse-observability.my.company.com:443
      endpoint: <otlp-suse-observability-endpoint:port>

  service:
    extensions: [health_check, bearertokenauth]
    pipelines:
      traces:
        receivers: [otlp]
        processors: [batch]
        exporters: [otlp]
      metrics:
        receivers: [otlp]
        processors: [batch]
        exporters: [otlp]
      logs:
        receivers: [otlp]
        processors: [batch]
        exporters: [otlp]

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: ingress-nginx-external
    nginx.ingress.kubernetes.io/ingress.class: ingress-nginx-external
    nginx.ingress.kubernetes.io/backend-protocol: GRPC
    # "12.34.56.78/32" IP address of NatGateway in the VPC where the otel data is originating from
    #  nginx.ingress.kubernetes.io/whitelist-source-range: "12.34.56.78/32"
  hosts:
    - host: "otlp-collector-proxy.<your-domain>"
      paths:
        - path: /
          pathType: ImplementationSpecific
          port: 4317
  tls:
    - secretName: <secret-for-tls-certificate>
      hosts:
        - "otlp-collector-proxy.<your-domain>"

# Instead of ingress:

# Alternative 1, load balancer service
#service:
#  type: LoadBalancer
#  loadBalancerSourceRanges: 12.34.56.78/32 # The IP address of NatGateway in the VPC for the lambda functions

# Alternative 2, node port service
#service:
#  type: NodePort
#ports:
#  otlp:
#    nodePort: 30317
----


Installez maintenant le collecteur en utilisant le fichier de configuration :

[,bash]
----
helm upgrade --install opentelemetry-collector open-telemetry/opentelemetry-collector \
  --values otel-collector.yaml \
  --namespace open-telemetry
----

Assurez-vous que le collecteur proxy est accessible par les fonctions Lambda, soit en ayant l'entrée accessible publiquement, soit en ayant l'IP du collecteur dans le même VPC que les fonctions Lambda.  Il est recommandé d'utiliser une liste blanche pour filtrer les données provenant de sources non fiables et/ou inconnues (voir le commentaire dans le fichier yaml). À côté de la configuration ingress, il est également possible d'exposer le collecteur aux fonctions Lambda via :

* un service LoadBalancer qui restreint l'accès en limitant les plages de sources, voir "Alternative 1".
* un service NodePort pour le collecteur, voir "Alternative 2".

Le collecteur offre beaucoup plus de configurations que les récepteurs, les transformateurs et les exportateurs. Pour plus de détails, voir notre xref:/setup/otel/collector.adoc[page sur le collecteur]. Dans le cas d'une utilisation en production, de grandes quantités de travées sont souvent générées et vous voudrez commencer à mettre en place un système d'xref:/setup/otel/sampling.adoc[échantillonnage].

== Instrumenter une fonction Lambda

Open Telemetry prend en charge l'instrumentation des fonctions Lambda dans plusieurs langues à l'aide de couches Lambda. La configuration de ces couches Lambda doit utiliser l'adresse du collecteur de l'étape précédente pour envoyer les données. Pour instrumenter une lambda Node.js, suivez nos xref:/setup/otel/instrumentation/node.js/auto-instrumentation-of-lambdas.adoc[instructions détaillées ici.] Pour instrumenter d'autres langages, appliquez la même configuration que pour Node.js mais utilisez l'une des autres https://opentelemetry.io/docs/platforms/faas/lambda-auto-instrument/[couches Lambda de].

== Voir les résultats

Allez sur SUSE Observability et assurez-vous que le Stackpack Open Telemetry est installé (via le menu principal \-> Stackpacks).

Après un court moment et si vos fonctions Lambda reçoivent un certain trafic, vous devriez être en mesure de trouver les fonctions sous leur nom de service dans les aperçus Open Telemetry \-> services et instances de service. Les traces apparaissent dans l'xref:/use/traces/k8sTs-explore-traces.adoc[explorateur de traces] et dans la xref:/use/views/k8s-traces-perspective.adoc[perspective de traces] pour les composants service et instance de service. Les métriques de portée et les métriques spécifiques à la langue (le cas échéant) seront disponibles dans la xref:/use/views/k8s-metrics-perspective.adoc[perspective des métriques] pour les composants.

== Prochaines étapes

ifdef::ss-ff-stackpacks2_enabled[]
Vous pouvez ajouter de nouveaux graphiques aux composants, par exemple le service ou l'instance de service, pour votre application, en suivant xref:/setup/custom-integrations/metric-bindings/index.adoc[notre guide.] Il est également possible de créer de xref:/use/alerting/k8s-monitors.adoc[nouveaux moniteurs] à l'aide des métriques et de configurer des xref:/use/alerting/notifications/configure.adoc[notifications] afin d'être informé lorsque votre application n'est pas disponible ou qu'elle présente des problèmes de performance.
endif::[]

ifndef::ss-ff-stackpacks2_enabled[]
Vous pouvez ajouter de nouveaux graphiques aux composants, par exemple le service ou l'instance de service, pour votre application, en suivant xref:/use/metrics/k8s-add-charts.adoc[notre guide.] Il est également possible de créer de xref:/use/alerting/k8s-monitors.adoc[nouveaux moniteurs] à l'aide des métriques et de configurer des xref:/use/alerting/notifications/configure.adoc[notifications] afin d'être informé lorsque votre application n'est pas disponible ou qu'elle présente des problèmes de performance.
endif::[]

== Plus d'informations

* xref:/use/security/k8s-service-tokens.adoc[Jetons de service]
* xref:/setup/otel/otlp-apis.adoc[API de télémétrie ouverte]
* xref:/setup/otel/collector.adoc[Personnalisation de la configuration du collecteur Open Telemetry]
* xref:/setup/otel/instrumentation/README.adoc[SDK de télémétrie ouverts]
