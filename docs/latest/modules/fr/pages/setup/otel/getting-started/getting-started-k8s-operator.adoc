= Démarrer avec l'opérateur Open Telemetry sur Kubernetes
:revdate: 2025-07-10
:page-revdate: {revdate}
:description: SUSE Observability

Voici la configuration que nous allons créer, pour une application qui doit être surveillée :

* L'application / charge de travail surveillée fonctionnant dans le cluster A, auto-instrumentée par l'opérateur
* L'opérateur de télémétrie ouverte du groupe A
* Un collecteur créé par l'opérateur
* SUSE Observability exécuté dans le cluster B, ou SUSE Cloud Observability

image::otel/open-telemetry-kubernetes-operator.png[Instrumentation du conteneur avec l'auto-instrumentation de l'opérateur Open Telemetry]

== Installer l'opérateur

L'opérateur Open Telemetry offre quelques fonctionnalités supplémentaires par rapport à la configuration normale de Kubernetes :

* Il peut auto-instrumenter vos pods d'application pour les langages pris en charge (Java, .NET, Python, Golang, Node.js), sans avoir à modifier les applications ou les images docker.
* Il peut remplacer l'opérateur Prometheus et commencer à récupérer les points d'extrémité de l'exportateur Prometheus sur la base des moniteurs de services et de pods.

=== Créer un jeton de service

Il existe deux façons de créer un jeton de service :

* **SUSE Observability UI** - ouvrez le menu principal en cliquant en haut à gauche de l'écran et allez à `StackPacks` > `Open Telemetry`.  Si vous ne l'avez pas encore fait, cliquez sur le bouton `INSTALL`.  Cliquez sur le bouton `CREATE NEW SERVICE TOKEN` et copiez la valeur dans votre presse-papiers.
* **SUSE Observability CLI** - voir xref:/use/security/k8s-service-tokens.adoc#_manage_service_tokens[Gérer les jetons de service]

La valeur du jeton de service doit être utilisée lorsque les instructions ci-dessous mentionnent `<SERVICE_TOKEN>`.

=== Créer l'espace de noms et un secret pour le jeton de service

Nous l'installerons dans l'espace de noms `open-telemetry` et utiliserons le jeton de service :

[,bash]
----
kubectl create namespace open-telemetry
kubectl create secret generic open-telemetry-collector \
    --namespace open-telemetry \
    --from-literal=API_KEY='<SERVICE_TOKEN>'
----

=== Configurer et installer l'opérateur

L'opérateur est installé avec une carte Helm, il faut donc d'abord configurer le dépôt de cartes.

[,bash]
----
helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts
----

Créons un fichier `otel-operator.yaml` pour configurer l'opérateur :

.otel-operator.yaml
[,yaml]
----
# Add image pull secret for private registries
imagePullSecrets: []
manager:
  image:
    # Uses chart.appVersion for the tag
    repository: ghcr.io/open-telemetry/opentelemetry-operator/opentelemetry-operator
  collectorImage:
    # find the latest collector releases at https://github.com/open-telemetry/opentelemetry-collector-releases/releases
    repository: otel/opentelemetry-collector-k8s
    tag: 0.123.0
  targetAllocatorImage:
    repository: ""
    tag: ""
  # Only needed when overriding the image repository, make sure to always specify both the image and tag:
  autoInstrumentationImage:
    java:
      repository: ""
      tag: ""
    nodejs:
      repository: ""
      tag: ""
    python:
      repository: ""
      tag: ""
    dotnet:
      repository: ""
      tag: ""
    # The Go instrumentation support in the operator is disabled by default.
    # To enable it, use the operator.autoinstrumentation.go feature gate.
    go:
      repository: ""
      tag: ""

admissionWebhooks:
  # A production setup should use certManager to generate the certificate, without certmanager the certificate will be generated during the Helm install
  certManager:
    enabled: false
  # The operator has validation and mutation hooks that need a certificate, with this we generate that automatically
  autoGenerateCert:
    enabled: true
----


Installez maintenant le collecteur en utilisant le fichier de configuration :

[,bash]
----
helm upgrade --install opentelemetry-operator open-telemetry/opentelemetry-operator \
  --namespace open-telemetry \
  --values otel-operator.yaml
----

Cette opération ne fait qu'installer l'opérateur. Poursuivre l'installation du collecteur et activer l'auto-instrumentation.

== Le collecteur de télémétrie ouvert

L'opérateur gère un ou plusieurs déploiements de collecteurs via une ressource personnalisée Kubernetes du type `OpenTelemetryCollector`. Nous allons en créer un en utilisant la même configuration que celle utilisée dans le xref:/setup/otel/getting-started/getting-started-k8s.adoc[guide de démarrage de Kubernetes].

Il utilise le secret créé plus tôt dans le guide. Veillez à remplacer `<otlp-suse-observability-endpoint:port>` par votre point de terminaison OTLP (voir xref:/setup/otel/otlp-apis.adoc[OTLP API] pour votre point de terminaison) et insérez le nom de votre cluster Kubernetes à la place de `<your-cluster-name>`:

.collector.yaml
[,yaml]
----
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector
spec:
  mode: deployment
  envFrom:
  - secretRef:
      name: open-telemetry-collector
  # optional service-account for pulling the collector image from a private registries
  # serviceAccount: otel-collector
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      # Scrape the collectors own metrics
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      # Use the API key from the env for authentication
      bearertokenauth:
        scheme: SUSEObservability
        token: "${env:API_KEY}"
    exporters:
      debug: {}
      nop: {}
      otlp/suse-observability:
        auth:
          authenticator: bearertokenauth
        # Put in your own otlp endpoint, for example otlp-suse-observability.my.company.com:443
        endpoint: <otlp-suse-observability-endpoint:port>
        compression: snappy
    processors:
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      batch: {}
      resource:
        attributes:
        - key: k8s.cluster.name
          action: upsert
          # Insert your own cluster name
          value: <your-cluster-name>
        - key: service.instance.id
          from_attribute: k8s.pod.uid
          action: insert
          # Use the k8s namespace also as the open telemetry namespace
        - key: service.namespace
          from_attribute: k8s.namespace.name
          action: insert
    connectors:
      # Generate metrics for spans
      spanmetrics:
        metrics_expiration: 5m
        namespace: otel_span
    service:
      extensions: [ health_check,  bearertokenauth ]
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, resource, batch]
          exporters: [debug, spanmetrics, otlp/suse-observability]
        metrics:
          receivers: [otlp, spanmetrics, prometheus]
          processors: [memory_limiter, resource, batch]
          exporters: [debug, otlp/suse-observability]
        logs:
          receivers: [otlp]
          processors: []
          exporters: [nop]
      telemetry:
        metrics:
          address: ${env:MY_POD_IP}:8888
----


[CAUTION]
====
*Utilisez le même nom de cluster que celui utilisé pour l'installation de l'agent SUSE Observability* si vous utilisez également l'agent SUSE Observability avec le stackpack Kubernetes. L'utilisation d'un nom de cluster différent se traduira par une perspective de traces vide pour les composants Kubernetes et rendra globalement la corrélation des informations beaucoup plus difficile pour SUSE Observability et vos utilisateurs.
====


Appliquez maintenant cette adresse `collector.yaml` dans l'espace de noms `open-telemetry` pour déployer un collecteur :

[,bash]
----
kubectl apply --namespace open-telemetry -f collector.yaml
----

Le collecteur offre beaucoup plus de configurations que les récepteurs, les transformateurs et les exportateurs. Pour plus de détails, voir notre xref:/setup/otel/collector.adoc[page sur le collecteur]. Dans le cas d'une utilisation en production, de grandes quantités de travées sont souvent générées et vous voudrez commencer à mettre en place un système d'xref:/setup/otel/sampling.adoc[échantillonnage].

== Auto-instrumentation

=== Configurer l'auto-instrumentation

Nous devons maintenant indiquer à l'opérateur comment configurer l'instrumentation automatique pour les différentes langues à l'aide d'une autre ressource personnalisée, du type `Instrumentation`. Il est principalement utilisé pour configurer le collecteur qui vient d'être déployé en tant que point final de télémétrie pour les applications instrumentées.

Il peut être défini à un seul endroit et utilisé par tous les pods du cluster, mais il est également possible d'avoir un `Instrumentation` différent dans chaque espace de noms. C'est ce que nous ferons ici. Notez que si vous avez utilisé un espace de noms différent ou un nom différent pour le collecteur otel, le point final de ce fichier doit être mis à jour en conséquence.

Créer un site `instrumentation.yaml`:

.instrumentation.yaml
[,yaml]
----
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: otel-instrumentation
spec:
  exporter:
    # default endpoint for the instrumentation
    endpoint: http://otel-collector-collector.open-telemetry.svc.cluster.local:4317
  propagators:
    - tracecontext
    - baggage
  defaults:
    # To use the standard app.kubernetes.io/ labels for the service name, version and namespace:
    useLabelsForResourceAttributes: true
  python:
    env:
      # Python autoinstrumentation uses http/proto by default, so data must be sent to 4318 instead of 4317.
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://otel-collector-collector.open-telemetry.svc.cluster.local:4318
  dotnet:
    env:
      # Dotnet autoinstrumentation uses http/proto by default, so data must be sent to 4318 instead of 4317.
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://otel-collector-collector.open-telemetry.svc.cluster.local:4318
  go:
    env:
      # Go autoinstrumentation uses http/proto by default, so data must be sent to 4318 instead of 4317.
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://otel-collector-collector.open-telemetry.svc.cluster.local:4318
----


Appliquez maintenant le `instrumentation.yaml` également dans l'espace de noms `open-telemetry`:

[,bash]
----
kubectl apply --namespace open-telemetry -f instrumentation.yaml
----

=== Activer l'auto-instrumentation pour un pod

Pour demander à l'opérateur d'auto-instrumenter vos pods d'application, nous devons ajouter une annotation au pod :

* Java : `instrumentation.opentelemetry.io/inject-java: open-telemetry/otel-instrumentation`
* NodeJS : `instrumentation.opentelemetry.io/inject-nodejs: open-telemetry/otel-instrumentation`
* Python : `instrumentation.opentelemetry.io/inject-python: open-telemetry/otel-instrumentation`
* Allez-y : `instrumentation.opentelemetry.io/inject-go: open-telemetry/otel-instrumentation`

Notez que la valeur de l'annotation fait référence à l'espace de noms et au nom de la ressource `Instrumentation` que nous avons créée. D'autres options sont possibles :

* "true" - injecter et `Instrumentation` une ressource personnalisée de l'espace de noms.
* "my-instrumentation" - nom de la ressource personnalisée `Instrumentation` dans l'espace de noms actuel.
* "my-other-namespace/my-instrumentation" - espace de noms et nom de la ressource personnalisée `Instrumentation` dans un autre espace de noms.
* "false" - ne pas injecter

Lorsqu'un pod avec l'une des annotations est créé, l'opérateur modifie le pod par le biais d'un crochet de mutation :

* Il ajoute un conteneur init qui fournit la bibliothèque d'auto-instrumentation
* Il modifie le premier conteneur du pod pour charger l'instrumentation au démarrage et ajoute des variables d'environnement pour configurer l'instrumentation.

Si vous devez personnaliser les conteneurs à instrumenter, utilisez la https://github.com/open-telemetry/opentelemetry-operator?tab=readme-ov-file#_multi_container_pods_with_multiple_instrumentations[documentation de l'opérateur].

[CAUTION]
====
L'auto-instrumentation Go nécessite des autorisations élevées. Ces autorisations sont définies automatiquement par l'opérateur :

[,yaml]
----
securityContext:
  privileged: true
  runAsUser: 0
----

====


== Voir les résultats

Allez sur SUSE Observability et assurez-vous que le Stackpack Open Telemetry est installé (via le menu principal \-> Stackpacks).

Après un court moment et si vos pods reçoivent du trafic, vous devriez pouvoir les trouver sous leur nom de service dans les aperçus Open Telemetry \-> services et instances de service. Les traces apparaissent dans l'xref:/use/traces/k8sTs-explore-traces.adoc[explorateur de traces] et dans la xref:/use/views/k8s-traces-perspective.adoc[perspective de traces] pour les composants service et instance de service. Les métriques de portée et les métriques spécifiques à la langue (le cas échéant) seront disponibles dans la xref:/use/views/k8s-metrics-perspective.adoc[perspective des métriques] pour les composants.

Si le stackpack Kubernetes est également installé, les pods instrumentés auront également les traces disponibles dans la xref:/use/views/k8s-traces-perspective.adoc[perspective de trace.]

== Rancher RBAC

Pour que xref:/setup/security/rbac/rbac_rancher.adoc[Rancher RBAC] fonctionne, les données télémétriques doivent avoir les attributs de ressources suivants :

* `k8s.cluster.name` - le nom du *cluster* tel qu'il est utilisé par le stackpack de Kubernetes.
* `k8s.namespace.name` - un *espace de noms* géré par un *projet* Rancher

L'opérateur Kubernetes injectera ces attributs par défaut dans toutes les données télémétriques envoyées.

== Prochaines étapes

ifdef::ss-ff-stackpacks2_enabled[]
Vous pouvez ajouter de nouveaux graphiques aux composants, par exemple le service ou l'instance de service, pour votre application, en suivant xref:/setup/custom-integrations/metric-bindings/index.adoc[notre guide.] Il est également possible de créer de xref:/use/alerting/k8s-monitors.adoc[nouveaux moniteurs] à l'aide des métriques et de configurer des xref:/use/alerting/notifications/configure.adoc[notifications] afin d'être informé lorsque votre application n'est pas disponible ou qu'elle présente des problèmes de performance.
endif::[]

ifndef::ss-ff-stackpacks2_enabled[]
Vous pouvez ajouter de nouveaux graphiques aux composants, par exemple le service ou l'instance de service, pour votre application, en suivant xref:/use/metrics/k8s-add-charts.adoc[notre guide.] Il est également possible de créer de xref:/use/alerting/k8s-monitors.adoc[nouveaux moniteurs] à l'aide des métriques et de configurer des xref:/use/alerting/notifications/configure.adoc[notifications] afin d'être informé lorsque votre application n'est pas disponible ou qu'elle présente des problèmes de performance.
endif::[]

L'opérateur, la ressource `OpenTelemetryCollector` et la ressource personnalisée `Instrumentation` ont plus d'options qui sont documentées dans le https://github.com/open-telemetry/opentelemetry-operator[readme] Par exemple, il est possible d'installer un https://github.com/open-telemetry/opentelemetry-operator?tab=readme-ov-file#_target_allocator[allocateur de cibles] optionnel via la ressource `OpenTelemetryCollector`, qui peut être utilisé pour configurer le récepteur Prometheus du collecteur. Ceci est particulièrement utile lorsque vous souhaitez remplacer l'opérateur Prometheus et que vous utilisez ses ressources personnalisées `ServiceMonitor` et `PodMonitor`.

== Plus d'informations

* xref:/use/security/k8s-service-tokens.adoc[Jetons de service]
* xref:/setup/otel/otlp-apis.adoc[API de télémétrie ouverte]
* xref:/setup/otel/collector.adoc[Personnalisation de la configuration du collecteur Open Telemetry]
* xref:/setup/otel/instrumentation/README.adoc[SDK de télémétrie ouverts]
* https://github.com/open-telemetry/opentelemetry-operator[Opérateur de télémétrie ouverte]
